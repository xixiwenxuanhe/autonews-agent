import requests
from datetime import datetime, timedelta
from .base_agent import BaseAgent
import time  # æ·»åŠ timeæ¨¡å—

class TechNewsAgent(BaseAgent):
    """ITç§‘æŠ€æ–°é—»æ™ºèƒ½ä½“"""
    
    def __init__(self):
        """åˆå§‹åŒ–ITç§‘æŠ€æ–°é—»æ™ºèƒ½ä½“"""
        super().__init__()
        self.categories = ["technology"]
        self.en_keywords = [
            # äººå·¥æ™ºèƒ½
            "artificial intelligence", "machine learning", "deep learning", "neural networks",
            "large language models", "LLM", "GPT", "natural language processing", "NLP",
            "computer vision", "robotics", "autonomous systems",
            
            # åŸºç¡€æŠ€æœ¯
            "software development", "programming", "cloud computing", "big data",
            "database", "system architecture", "cybersecurity",
            
            # æ–°å…´æŠ€æœ¯
            "blockchain", "cryptocurrency", "metaverse", "augmented reality", "AR",
            "virtual reality", "VR", "quantum computing", "edge computing",
            
            # ç§»åŠ¨ä¸æ¶ˆè´¹ç”µå­
            "smartphone", "mobile technology", "wearable tech", "5G", "6G"
        ]
        
        self.zh_keywords = [
            # äººå·¥æ™ºèƒ½
            "äººå·¥æ™ºèƒ½", "æœºå™¨å­¦ä¹ ", "æ·±åº¦å­¦ä¹ ", "ç¥ç»ç½‘ç»œ", "å¤§æ¨¡å‹", "å¤§è¯­è¨€æ¨¡å‹",
            "è‡ªç„¶è¯­è¨€å¤„ç†", "è®¡ç®—æœºè§†è§‰", "æœºå™¨äºº", "è‡ªåŠ¨é©¾é©¶", "æ™ºèƒ½åŠ©æ‰‹",
            
            # åŸºç¡€æŠ€æœ¯
            "è½¯ä»¶å¼€å‘", "ç¼–ç¨‹", "äº‘è®¡ç®—", "å¤§æ•°æ®", "æ•°æ®åº“", "ç³»ç»Ÿæ¶æ„", "ç½‘ç»œå®‰å…¨",
            
            # æ–°å…´æŠ€æœ¯
            "å…ƒå®‡å®™", "å¢å¼ºç°å®", "è™šæ‹Ÿç°å®", "é‡å­è®¡ç®—", "è¾¹ç¼˜è®¡ç®—",
            
            # ç§»åŠ¨ä¸æ¶ˆè´¹ç”µå­
            "æ™ºèƒ½æ‰‹æœº", "ç§»åŠ¨æŠ€æœ¯", "å¯ç©¿æˆ´è®¾å¤‡", "5G", "6G"
        ]
    
    def collect_news(self, max_articles=5):
        """æ”¶é›†ITç§‘æŠ€ç›¸å…³æ–°é—»ï¼ŒåŒ…æ‹¬ä¸­è‹±æ–‡å„5æ¡
        
        Args:
            max_articles (int): æ¯ç§è¯­è¨€çš„æœ€å¤§æ–‡ç« æ•°é‡
            
        Returns:
            list: æ–°é—»æ–‡ç« åˆ—è¡¨
        """
        print(f"[{datetime.now().strftime('%H:%M:%S')}] ğŸ“± æ”¶é›†ITç§‘æŠ€æ–°é—»...")
        
        # è·å–å½“å‰æ—¥æœŸå’Œå‰ä¸€å¤©çš„æ—¥æœŸ
        today = datetime.now()
        yesterday = today - timedelta(days=1)
        from_date = yesterday.strftime('%Y-%m-%d')
        
        # è·å–è‹±æ–‡æ–°é—»
        english_news = self._collect_language_news(self.en_keywords, "en", max_articles)
        
        # è·å–ä¸­æ–‡æ–°é—» - å¤šè·å–ä¸€äº›ä»¥ä¾¿è¿‡æ»¤ç¹ä½“
        zh_max = max_articles * 2  # è·å–æ›´å¤šä¸­æ–‡æ–°é—»ä»¥ä¾¿è¿‡æ»¤ç¹ä½“
        chinese_news = self._collect_language_news(self.zh_keywords, "zh", zh_max)
        
        # è¿‡æ»¤ç¹ä½“ä¸­æ–‡æ–°é—»
        simplified_chinese_news = []
        filtered_count = 0
        
        for news in chinese_news:
            # æ£€æŸ¥æ ‡é¢˜å’Œæè¿°æ˜¯å¦åŒ…å«ç¹ä½“ä¸­æ–‡
            title = news.get('title', '')
            desc = news.get('description', '')
            
            if self.is_traditional_chinese(title) or self.is_traditional_chinese(desc):
                filtered_count += 1
                continue
            
            simplified_chinese_news.append(news)
            
            # å¦‚æœå·²ç»æ”¶é›†äº†è¶³å¤Ÿæ•°é‡çš„ç®€ä½“ä¸­æ–‡æ–°é—»ï¼Œå°±åœæ­¢
            if len(simplified_chinese_news) >= max_articles:
                break
        
        if filtered_count > 0:
            print(f"[{datetime.now().strftime('%H:%M:%S')}] ğŸ“± å·²è¿‡æ»¤ {filtered_count} æ¡ç¹ä½“ä¸­æ–‡æ–°é—»")
        
        # ç¡®ä¿ä¸è¶…è¿‡max_articlesæ•°é‡
        simplified_chinese_news = simplified_chinese_news[:max_articles]
        
        # åˆå¹¶ç»“æœ
        combined_news = english_news + simplified_chinese_news
        print(f"[{datetime.now().strftime('%H:%M:%S')}] ğŸ“± æ”¶é›†å®Œæˆ: {len(combined_news)} æ¡ (è‹±:{len(english_news)}, ä¸­:{len(simplified_chinese_news)})")
        return combined_news
    
    def _collect_language_news(self, keywords, language, max_articles):
        """æ”¶é›†ç‰¹å®šè¯­è¨€çš„æ–°é—»
        
        Args:
            keywords (list): æœç´¢å…³é”®è¯åˆ—è¡¨
            language (str): è¯­è¨€ä»£ç ï¼Œ'en'ä¸ºè‹±æ–‡ï¼Œ'zh'ä¸ºä¸­æ–‡
            max_articles (int): æœ€å¤§æ–‡ç« æ•°é‡
            
        Returns:
            list: è¯¥è¯­è¨€çš„æ–°é—»æ–‡ç« åˆ—è¡¨
        """
        lang_label = "è‹±æ–‡" if language == "en" else "ä¸­æ–‡"
        print(f"[{datetime.now().strftime('%H:%M:%S')}] ğŸ“± è·å–{lang_label}ç§‘æŠ€æ–°é—»...")
        
        # å¯¼å…¥éšæœºæ¨¡å—
        import random
        import time  # æ·»åŠ timeæ¨¡å—
        
        # éšæœºæ‰“ä¹±å…³é”®è¯é¡ºåº
        shuffled_keywords = keywords.copy()
        random.shuffle(shuffled_keywords)
        
        # å­˜å‚¨æ‰€æœ‰æ‰¹æ¬¡è·å–çš„æ–‡ç« 
        all_articles = []
        
        # æ„å»ºNewsAPIè¯·æ±‚URL
        base_url = "https://newsapi.org/v2/everything"
        
        # æ¯æ¬¡åªä½¿ç”¨ä¸¤ä¸ªå…³é”®è¯
        for i in range(0, len(shuffled_keywords), 2):
            if i + 1 >= len(shuffled_keywords):
                break
                
            batch_keywords = shuffled_keywords[i:i+2]
            print(f"[{datetime.now().strftime('%H:%M:%S')}] ğŸ“± ä½¿ç”¨å…³é”®è¯: {', '.join(batch_keywords)}")
            
            # æ„å»ºæŸ¥è¯¢å…³é”®è¯
            query = " OR ".join(batch_keywords)
            
            # è®¾ç½®è¯·æ±‚å‚æ•°
            params = {
                "apiKey": self.news_api_key,
                "q": query,
                "from": (datetime.now() - timedelta(days=1)).strftime('%Y-%m-%d'),
                "language": language,
                "sortBy": "relevancy",
                "pageSize": 2  # æ¯æ‰¹æ¬¡è·å–å›ºå®šæ•°é‡çš„æ–‡ç« 
            }
            
            try:
                # å‘é€è¯·æ±‚
                response = requests.get(base_url, params=params)
                response.raise_for_status()
                data = response.json()
                
                # è·å–æ–‡ç« åˆ—è¡¨
                batch_articles = data.get("articles", [])
                print(f"[{datetime.now().strftime('%H:%M:%S')}] ğŸ“± è·å–åˆ° {len(batch_articles)} ç¯‡æ–‡ç« ")
                
                # å°†è¯¥æ‰¹æ¬¡çš„æ–‡ç« æ·»åŠ åˆ°æ€»æ–‡ç« åˆ—è¡¨ä¸­
                all_articles.extend(batch_articles)
                
                # å¦‚æœå·²ç»è·å–è¶³å¤Ÿå¤šçš„æ–‡ç« ï¼Œå¯ä»¥æå‰é€€å‡º
                if len(all_articles) >= 10:  # è·å–10ç¯‡æ–‡ç« ååœæ­¢
                    print(f"[{datetime.now().strftime('%H:%M:%S')}] ğŸ“± å·²è·å–è¶³å¤Ÿå¤šçš„æ–‡ç«  ({len(all_articles)} ç¯‡)ï¼Œåœæ­¢æŸ¥è¯¢")
                    break
                    
                # æ·»åŠ è¯·æ±‚é—´éš”ï¼Œé¿å…è§¦å‘APIé™åˆ¶
                time.sleep(1)  # æ¯æ¬¡è¯·æ±‚åç­‰å¾…1ç§’
                    
            except Exception as e:
                print(f"[{datetime.now().strftime('%H:%M:%S')}] âŒ è·å–{lang_label}ç§‘æŠ€æ–°é—»å¤±è´¥: {e}")
                # å¦‚æœé‡åˆ°é”™è¯¯ï¼Œç­‰å¾…æ›´é•¿æ—¶é—´å†é‡è¯•
                time.sleep(5)
        
        # å»é™¤å¯èƒ½çš„é‡å¤æ–‡ç« ï¼ˆåŸºäºURLï¼‰
        unique_articles = []
        seen_urls = set()
        
        for article in all_articles:
            url = article.get("url", "")
            if url and url not in seen_urls:
                seen_urls.add(url)
                unique_articles.append(article)
        
        print(f"[{datetime.now().strftime('%H:%M:%S')}] ğŸ“± å»é‡åå…± {len(unique_articles)} ç¯‡{lang_label}æ–‡ç« ")
        
        # ä½¿ç”¨LLMç­›é€‰æœ€ç›¸å…³çš„æ–‡ç« 
        if unique_articles:
            return self._filter_relevant_articles(unique_articles, max_articles, lang_label)
        else:
            print(f"[{datetime.now().strftime('%H:%M:%S')}] ğŸ“± æœªè·å–åˆ°{lang_label}æ–‡ç« ")
            return []
    
    def _filter_relevant_articles(self, articles, max_articles, language_label=""):
        """ä½¿ç”¨LLMç­›é€‰æœ€ç›¸å…³çš„æ–‡ç« 
        
        Args:
            articles (list): åŸå§‹æ–‡ç« åˆ—è¡¨
            max_articles (int): æœ€å¤§è¿”å›æ–‡ç« æ•°é‡
            language_label (str): è¯­è¨€æ ‡ç­¾ï¼Œç”¨äºæ—¥å¿—
            
        Returns:
            list: ç­›é€‰åçš„æ–‡ç« åˆ—è¡¨
        """
        # å¦‚æœæ–‡ç« æ•°é‡å°‘äºmax_articlesï¼Œç›´æ¥è¿”å›æ‰€æœ‰æ–‡ç« 
        if len(articles) <= max_articles:
            return self._format_articles(articles, language_label)
        
        # æ„å»ºæç¤ºè¯
        article_summaries = []
        for i, article in enumerate(articles[:10]):  # åªå¤„ç†å‰10ç¯‡æ–‡ç« 
            title = article.get("title", "æ— æ ‡é¢˜")
            description = article.get("description", "æ— æè¿°")
            article_summaries.append(f"{i+1}. æ ‡é¢˜: {title}\n   æè¿°: {description}")
        
        article_text = "\n\n".join(article_summaries)
        
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ITç§‘æŠ€æ–°é—»ç¼–è¾‘ï¼Œè¯·ä»ä»¥ä¸‹{language_label}ITç§‘æŠ€æ–°é—»ä¸­é€‰æ‹©{max_articles}ç¯‡æœ€é‡è¦ã€æœ€æœ‰å½±å“åŠ›çš„æ–‡ç« ï¼Œå®ƒä»¬åº”è¯¥æ¶µç›–é‡è¦æŠ€æœ¯çªç ´ã€äº§ä¸šåŠ¨æ€æˆ–å…·æœ‰å¹¿æ³›å½±å“çš„ITæ–°é—»ã€‚

è¯·æ³¨æ„ï¼Œäººå·¥æ™ºèƒ½(AI)ã€æœºå™¨å­¦ä¹ ã€å¤§æ¨¡å‹ã€è‡ªç„¶è¯­è¨€å¤„ç†ã€è®¡ç®—æœºè§†è§‰ç­‰é¢†åŸŸéƒ½å±äºç§‘æŠ€ç±»åˆ«ï¼Œåº”ä¼˜å…ˆé€‰æ‹©è¿™äº›é¢†åŸŸçš„æ–°é—»ã€‚æ­¤å¤–ï¼Œè½¯ä»¶å¼€å‘ã€ç¡¬ä»¶æŠ€æœ¯ã€äº‘è®¡ç®—ã€æ•°æ®ç§‘å­¦ã€åŒºå—é“¾ã€å…ƒå®‡å®™ã€VR/ARã€ç‰©è”ç½‘ã€5G/6Gç­‰æŠ€æœ¯åˆ›æ–°ä¹Ÿå±äºç§‘æŠ€èŒƒç•´ã€‚

æ–°é—»åˆ—è¡¨:
{article_text}

è¯·åªè¿”å›ä½ é€‰æ‹©çš„æ–‡ç« åºå·ï¼Œæ ¼å¼ä¸ºé€—å·åˆ†éš”çš„æ•°å­—ï¼Œä¾‹å¦‚: 1,3,5
"""
        
        # è°ƒç”¨LLM API
        print(f"[{datetime.now().strftime('%H:%M:%S')}] ğŸ“± ç­›é€‰{language_label}æ–‡ç« ä¸­...")
        response = self.call_llm_api(prompt, temperature=0.3)
        
        try:
            # è§£æå“åº”ï¼Œè·å–é€‰ä¸­çš„æ–‡ç« ç´¢å¼•
            selected_indices = []
            for item in response.replace(" ", "").split(","):
                if item.isdigit() and 1 <= int(item) <= len(articles):
                    selected_indices.append(int(item) - 1)
            
            # æˆªå–è‡³max_articles
            selected_indices = selected_indices[:max_articles]
            
            # è¿”å›é€‰ä¸­çš„æ–‡ç« 
            selected_articles = [articles[i] for i in selected_indices]
            
            return self._format_articles(selected_articles, language_label)
            
        except Exception as e:
            print(f"[{datetime.now().strftime('%H:%M:%S')}] âŒ è§£æLLMå“åº”å¤±è´¥: {e}")
            # å‡ºé”™æ—¶è¿”å›å‰max_articlesç¯‡æ–‡ç« 
            return self._format_articles(articles[:max_articles], language_label)
    
    def _format_articles(self, articles, language_label=""):
        """æ ¼å¼åŒ–æ–‡ç« ä¸ºç»Ÿä¸€è¾“å‡ºæ ¼å¼
        
        Args:
            articles (list): åŸå§‹æ–‡ç« åˆ—è¡¨
            language_label (str): è¯­è¨€æ ‡ç­¾
            
        Returns:
            list: æ ¼å¼åŒ–åçš„æ–‡ç« åˆ—è¡¨
        """
        formatted_articles = []
        for article in articles:
            formatted_article = {
                "title": article.get("title", "æ— æ ‡é¢˜"),
                "description": article.get("description", "æ— æè¿°"),
                "url": article.get("url", ""),
                "source": article.get("source", {}).get("name", "æœªçŸ¥æ¥æº"),
                "published_at": article.get("publishedAt", ""),
                "category": "ITç§‘æŠ€",
                "language": language_label
            }
            formatted_articles.append(formatted_article)
        
        return formatted_articles 